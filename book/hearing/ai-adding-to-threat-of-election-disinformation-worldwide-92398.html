<!DOCTYPE html>
<html>
<head><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/>
<meta charset="utf-8"/>
<title>VOA Special English - AI Adding to Threat of Election Disinformation Worldwide</title>
<meta content="all" name="robots"/>
<meta content="慢速英语,VOA Special English" name="keywords"/>
<meta content="VOA Special English, Technology Report, AI Adding to Threat of Election Disinformation Worldwide" name="description"/>
<link href="./static/css/2024.css" rel="stylesheet" type="text/css"/>
<link href="./static/css/jplayer.css" rel="stylesheet" type="text/css"/>
<script src="./static/js/jquery.min.js" type="text/javascript"></script>
<script src="./static/js/posfixed.js" type="text/javascript"></script>
<script src="./static/js/lrc.js" type="text/javascript"></script>
<script src="./static/js/jquery.jplayer.min.js" type="text/javascript"></script>
</head>
<body>
<script>
//var page_next ="";
$(document).ready(function(){
    $("#jquery_jplayer_1").jPlayer({
        ready: function (event) {
            $(this).jPlayer("setMedia", {
                mp3:"https://files.21voa.com/audio/202403/ai-adding-to-threat-of-election-disinformation-worldwide.mp3" //mp3的播放地址
            }).jPlayer("repeat");
            $.lrc.init($('#lrc_content').val());
			if(newlrc.get_query('auto')==1){
                $(this).jPlayer("play");
            }
               newlrc.do_ploop();
        },
        timeupdate: function(event) {
            if(event.jPlayer.status.currentTime==0){
                time = 0.1;
            }else {
                time = event.jPlayer.status.currentTime;
            }
        },
        play: function(event) {
            $.lrc.start(function() {
                return time;
            });
            newlrc.fstart = 1;
        },
        ended2:function(event){
                if(newlrc.ploop==1 && page_next !=''){
                //window.location.href=page_next;
                return;
            }
            $.lrc.init($('#lrc_content').val());
            newlrc.fstart = 0;
        },
        pause: function (event){
            if(event.jPlayer.status.currentTime==0){
                $.lrc.init($('#lrc_content').val());
            }
            newlrc.fstart = 0;
        },
        repeat2: function (event){
        },
		repeat : function (event){
            if(event.jPlayer.options.loop) {
                $(this).unbind(".jPlayerRepeat").bind($.jPlayer.event.ended + ".jPlayer.jPlayerRepeat", function() {
                    $(this).jPlayer("play");
                });
                newlrc.cancle_ploop();
            } else {
                $(this).unbind(".jPlayerRepeat");
            }
        },
		swfPath: "/static/js/",
		solution:"html, flash", //支持的页面
		supplied: "mp3",        //支持的音频的格式
		wmode: "window",
                volume: 0.8, 
		useStateClassSkin: true,
		autoBlur: false,
		smoothPlayBar: true,
		keyEnabled: true,
		remainingDuration: true,
		toggleDuration: true
    	});
});
        var newlrc = {
        fstart:0,
        floop:0,
        jp : $("#jquery_jplayer_1"),
        jump: function (t){
            this.jp.jPlayer("play",t);
        },
        pause: function(){
            this.jp.jPlayer("pause");
        },
        play: function(){
            this.jp.jPlayer("play");

        },
        loop_one: function(){
            
        },
        loop: function(){
			        },
        ploop :0,
        doloop: function(){
            this.jp.jPlayer("option",'loop',true);
        },
        
        cancle_loop : function (){
            this.jp.jPlayer("option",'loop',false);
        },
        do_ploop: function(){
            if(this.ploop==1){
                return;
            }
            this.ploop = 1;
            this.cancle_loop(); //将单曲循环取消
            this.ploop_show();
        },
        cancle_ploop : function(){
            if(this.ploop==0){
                return;
            }
            this.ploop = 0;
            this.ploop_show();
        },
        ploop_show : function(){
            $(".l_do_loop").toggle();
            $(".l_cancle_loop").toggle();
        },
        get_query : function (name) {
            var reg = new RegExp("(^|&)" + name + "=([^&]*)(&|$)", "i");
            var r = window.location.search.substr(1).match(reg);
            if (r != null) {
                return unescape(r[2]);
            }
            return null;
        }        
}
</script>
<script>
$(function(){
	$('.jplayer').posfixed({
		distance : 0,
		pos : 'top',
		type : 'while',
		tag : {
			obj : $('.content_top'),
			direction : 'right',
			distance : 20
		},
		hide : false
	});
});
</script>
<div id="main">
<div id="righter">
<div class="title"><h1>AI Adding to Threat of Election Disinformation Worldwide</h1></div>
<div class="jplayer">
<div class="jp-jplayer" id="jquery_jplayer_1"></div>
<div aria-label="media player" class="jp-audio" id="jp_container_1" role="application">
<div class="jp-type-single">
<div class="jp-gui jp-interface">
<div class="jp-controls">
<button class="jp-play" role="button" tabindex="0">play</button>
<button class="jp-stop" role="button" tabindex="0">stop</button>
</div>
<div class="jp-progress">
<div class="jp-seek-bar">
<div class="jp-play-bar"></div>
</div>
</div>
<div class="jp-volume-controls">
<button class="jp-mute" role="button" tabindex="0">mute</button>
<button class="jp-volume-max" role="button" tabindex="0">max volume</button>
<div class="jp-volume-bar">
<div class="jp-volume-bar-value"></div>
</div>
</div>
<div class="jp-time-holder">
<div aria-label="time" class="jp-current-time" role="timer"> </div>
<div aria-label="duration" class="jp-duration" role="timer"> </div>
<div class="jp-toggles">
<button class="jp-repeat" role="button" tabindex="0">repeat</button>
<div class="menubar">
<a href="https://files.21voa.com/audio/202403/ai-adding-to-threat-of-election-disinformation-worldwide.mp3" id="mp3"></a>
<a href="/static/lrc/ai-adding-to-threat-of-election-disinformation-worldwide.lrc" id="lrc"></a>
<a href="india-implements-much-debated-new-citizenship-law-92396.html" id="next"></a>
<a href="/static/help.html" id="help" target="_blank"></a> <a href="/static/report.html" id="report" target="_blank"></a>
</div>
</div>
</div>
</div>
<div class="jp-no-solution">
<span>Update Required</span>
			To play the media you will need to either update your browser to a recent version or update your <a href="http://get.adobe.com/flashplayer/" target="_blank">Flash plugin</a>.
		</div>
</div>
</div>
</div>
<div class="lrc_box"><ul id="lrc_list"></ul></div>
<div class="content">

<p>Artificial intelligence (AI) is adding to the threat of election disinformation worldwide.</p>
<p>The technology makes it easy for anyone with a smartphone and an imagination to create <strong>fake </strong>– but convincing – content aimed at fooling voters.</p>
<p>Just a few years ago, fake photos, videos or audio required teams of people with time, skill and money. Now, free and low-cost generative artificial intelligence services from companies like Google and OpenAI permit people to create high-quality "deepfakes" with just a simple text entry.</p><div class="contentImage"><img alt="FILE - An advertising banner with a slogan about AI is fixed at a building at the Davos Promenade, alongside the World Economic Forum in Davos, Switzerland, Jan. 18, 2024. (AP Photo/Markus Schreiber, File)" src="https://files.21voa.com/gdb/1395462a-a385-4366-8108-5652f0125761_w268_r1.jpg"/><br/><span class="imagecaption">FILE - An advertising banner with a slogan about AI is fixed at a building at the Davos Promenade, alongside the World Economic Forum in Davos, Switzerland, Jan. 18, 2024. (AP Photo/Markus Schreiber, File)</span></div>
<p><strong>Expanding threats</strong></p>
<p>A wave of AI deepfakes tied to elections in Europe and Asia has already appeared on social media for months. It served as a warning for more than 50 countries having elections this year.</p>
<p>Some recent examples of AI deepfakes include:</p>
<p>— A video of Moldova's pro-Western president throwing her support behind a political party friendly to Russia.</p>
<p>— Audio of Slovakia's liberal party leader discussing changing ballots and raising the price of beer.</p>
<p>— A video of an opposition lawmaker in Bangladesh — a conservative Muslim majority nation — wearing a <strong>bikini</strong>.</p>
<p>The question is no longer whether AI deepfakes could affect elections, but how influential they will be, said Henry Ajder, who runs a business advisory company called Latent Space Advisory in Britain.</p>
<p>"You don't need to look far to see some people ... being clearly confused as to whether something is real or not," Ajder said.</p>
<p><strong>Challenge to democracy</strong></p>
<p>As the U.S. presidential race comes closer, Christopher Wray, the director of the Federal Bureau of Investigation issued a warning about the growing threat of generative AI. He said the technology makes it easy for foreign groups to attempt to have a bad influence on elections.</p>
<p>With AI deepfakes, a candidate's image can be made much worse or much better. Voters can be moved toward or away from candidates — or even to avoid the polls altogether. But perhaps the greatest threat to democracy, experts say, is that the growth of AI deepfakes could hurt the public's trust in what they see and hear.</p>
<p>The complexity of the technology makes it hard to find out who is behind AI deepfakes. Experts say governments and companies are not yet capable of stopping the problem.</p>
<p>The world's biggest tech companies recently — and voluntarily — signed an agreement to prevent AI tools from disrupting elections. For example, the company that owns Instagram and Facebook has said it will start <strong>labeling</strong> deepfakes that appear on its services.</p>
<p>But deepfakes are harder to limit on apps like Telegram, which did not sign the voluntary agreement. Telegram uses <strong>encrypted </strong>messages that can be difficult to uncover.</p>
<p><strong>Concerns about efforts to limit AI</strong></p>
<p>Some experts worry that efforts to limit AI deepfakes could lead to unplanned results.</p>
<p>Tim Harper is an expert at the Center for Democracy and Technology in Washington, DC. He said sometimes well-meaning governments or companies might crush the "very thin" line between political commentary and an "<strong>illegitimate </strong>attempt to<strong> smear </strong>a candidate."</p>
<p>Major generative AI services have rules to limit political disinformation. But experts say it is too easy to defeat the restrictions or use other services.</p>
<p>AI software is not the only threat.</p>
<p>Candidates themselves could try to fool voters by claiming events that show them in bad situations were manufactured by AI.</p>
<p>Lisa Reppell is a researcher at the International Foundation for Electoral Systems in Arlington, Virginia.</p>
<p>She said, "A world in which everything is suspect — and so everyone gets to choose what they believe — is also a world that's really challenging for...democracy."</p>
<p>I'm John Russell.</p>
<p><em>Ali Swenson and Kelvin Chan reported on this story for the Associated Press. John Russell adapted it for VOA Learning English.</em></p>
<p>_______________________________________</p>
<h2 class="wsw__h2"><strong>Words in This Story</strong></h2>
<p><strong>fake </strong>– n. not true or real</p>
<p><strong>bikini </strong><em>-- n.</em><strong> </strong>a piece of clothing in two parts that a woman wears for swimming</p>
<p><strong>label </strong><em>-- v. </em>to use a word or phrase that describes or identifies something or someone</p>
<p><strong>encrypted -</strong><em>- v.</em><strong> </strong>to change (information) from one form to another</p>
<p><strong>illegitimate </strong><em>-- adj. </em> not allowed according to rules or laws</p>
<p><strong>smear </strong><em>-- v.</em><strong> </strong> to make untrue statements about someone</p>
</div>
<textarea id="lrc_content" name="textfield" style="display:none;">[ti:AI Adding to Threat of Election Disinformation Worldwide]
[by:www.21voa.com]
[00:00.00]快捷键：S播放/暂停，A快退，D快进，W循环。
[00:00.04]Artificial intelligence (AI)
[00:04.04]is adding to the threat
[00:06.08]of election disinformation worldwide.
[00:09.80]The technology makes it easy
[00:12.48]for anyone with a smartphone
[00:15.24]and an imagination to create fake – but convincing
[00:20.12]– content aimed at fooling voters.
[00:23.48]Just a few years ago, fake photos,
[00:27.04]videos or audio required
[00:30.04]teams of people with time, skill and money.
[00:35.12]Now, free and low-cost
[00:38.04]generative artificial intelligence services
[00:41.40]from companies like Google and OpenAI
[00:45.40]permit people to create high-quality
[00:48.40]"deepfakes" with just a simple text entry.
[00:52.64]A wave of AI deepfakes tied
[00:55.80]to elections in Europe and Asia
[00:58.84]has already appeared on social media for months.
[01:03.08]It served as a warning for more than 50 countries
[01:07.72]having elections this year.
[01:10.32]Some recent examples of AI deepfakes include:
[01:14.88]— A video of Moldova's pro-Western president
[01:19.16]throwing her support behind
[01:21.16]a political party friendly to Russia.
[01:24.44]— Audio of Slovakia's liberal party leader
[01:28.24]discussing changing ballots
[01:30.44]and raising the price of beer.
[01:33.36]— A video of an opposition lawmaker in Bangladesh
[01:37.68]— a conservative Muslim majority nation
[01:40.88]— wearing a bikini.
[01:42.64]The question is no longer whether AI deepfakes
[01:46.76]could affect elections,
[01:48.76]but how influential they will be, said Henry Ajder,
[01:53.12]who runs a business advisory company
[01:55.80]called Latent Space Advisory in Britain.
[01:59.60]"You don't need to look far to see some people
[02:03.32]... being clearly confused
[02:05.44]as to whether something is real or not," Ajder said.
[02:10.72]As the U.S. presidential race comes closer,
[02:13.96]Christopher Wray, the director of
[02:16.44]the Federal Bureau of Investigation
[02:19.40]issued a warning about the growing threat
[02:22.88]of generative AI.
[02:25.28]He said the technology
[02:27.00]makes it easy for foreign groups to attempt
[02:30.56]to have a bad influence on elections.
[02:34.36]With AI deepfakes, a candidate's image
[02:38.08]can be made much worse or much better.
[02:42.28]Voters can be moved
[02:43.76]toward or away from candidates
[02:46.52]— or even to avoid the polls altogether.
[02:50.32]But perhaps the greatest threat
[02:52.40]to democracy, experts say,
[02:55.12]is that the growth of AI deepfakes
[02:58.16]could hurt the public's trust
[03:00.40]in what they see and hear.
[03:02.64]The complexity of the technology
[03:05.56]makes it hard to find out
[03:07.28]who is behind AI deepfakes.
[03:10.00]Experts say governments and companies
[03:13.76]are not yet capable of stopping the problem.
[03:17.12]The world's biggest tech companies
[03:19.84]recently — and voluntarily — signed an agreemen
[03:24.16]t to prevent AI tools from disrupting elections.
[03:28.52]For example,
[03:30.36]the company that owns Instagram and Facebook
[03:33.76]has said it will start labeling deepfakes
[03:37.28]that appear on its services.
[03:40.24]But deepfakes are harder
[03:42.24]to limit on apps like Telegram,
[03:44.84]which did not sign the voluntary agreement.
[03:49.00]Telegram uses encrypted messages
[03:52.24]that can be difficult to uncover.
[03:55.20]Some experts worry that efforts to limit AI deepfakes
[04:00.08]could lead to unplanned results.
[04:04.12]Tim Harper is an expert at the Center for Democracy
[04:08.32]and Technology in Washington, DC.
[04:11.64]He said sometimes well-meaning governments
[04:14.88]or companies might crush the "very thin" line
[04:18.88]between political commentary
[04:21.24]and an "illegitimate attempt to smear a candidate."
[04:26.60]Major generative AI services
[04:29.32]have rules to limit political disinformation.
[04:33.12]But experts say it is too easy
[04:36.12]to defeat the restrictions or use other services.
[04:40.64]AI software is not the only threat.
[04:44.04]Candidates themselves could try to fool voters
[04:48.08]by claiming events that show them
[04:50.64]in bad situations were manufactured by AI.
[04:55.20]Lisa Reppell is a researcher
[04:58.20]at the International Foundation
[05:00.60]for Electoral Systems in Arlington, Virginia.
[05:04.76]She said, "A world in which everything is suspect
[05:08.84]— and so everyone gets to choose
[05:10.88]what they believe — is also a world
[05:13.72]that's really challenging for...democracy."
[05:18.20]I'm John Russell. 

</textarea>
</div></div>
<div class="clearing"></div>
</body></html>